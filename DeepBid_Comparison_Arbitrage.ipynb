{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"YbRIEKC7Ikih"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DR-OCqAxImPV"},"outputs":[],"source":["RE = \"Solar_PBE\"\n","\n","data_train_csv1 = pd.read_csv(\"data/\"+RE+'_16.csv', index_col=0)\n","data_train_csv2 = pd.read_csv(\"data/\"+RE+'_17.csv', index_col=0)\n","data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n","data_val_csv    = pd.read_csv(\"data/\"+RE+'_18.csv', index_col=0)\n","data_test_csv   = pd.read_csv(\"data/\"+RE+'_19.csv', index_col=0)\n","\n","data_price = pd.read_csv(\"data/\"+'Price_Elia_Imbalance_16_19.csv', index_col=0)\n","data_train_csv['Price(€)'] = data_price['Positive imbalance price'][:len(data_train_csv)]\n","data_val_csv['Price(€)']   = data_price['Positive imbalance price'][len(data_train_csv):len(data_train_csv)+len(data_val_csv)]\n","data_test_csv['Price(€)']  = data_price['Positive imbalance price'][len(data_train_csv)+len(data_val_csv):]\n","\n","train_predict = [0.0] + np.array(pd.read_csv(RE+\"_Model4_DeepBid.csv\", index_col=0)).flatten().tolist()\n","val_predict   = [0.0] + np.array(pd.read_csv(RE+\"_Model4_DeepBid.csv\", index_col=0)).flatten().tolist()\n","test_predict  = [0.0] + np.array(pd.read_csv(RE+\"_Model4_DeepBid.csv\", index_col=0)).flatten().tolist()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eiXqkJByIr87"},"outputs":[],"source":["# Data Preprocessing\n"," \n","Battery_Size = 0.15 #p.u.\n","unit         = 1 #unit: 15 minute\n"," \n","RE_Capacity1 = max(data_train_csv['Power(MW)'])\n","RE_Capacity2 = max(data_val_csv['Power(MW)'])\n","RE_Capacity3 = max(data_test_csv['Power(MW)'])\n","max_price = max(data_price['Marginal incremental price'])\n"," \n","size_train0 = int(len(data_train_csv)/unit)\n","size_val0   = int(len(data_val_csv)/unit)\n","size_test0  = int(len(data_test_csv)/unit)\n"," \n","data_train0 = []; data_train = []; price_train0 = []; price_train = [];\n","for i in range(size_train0):\n","    data_train0  += [round(pd.Series.mean(data_train_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n","    price_train0 += [round(pd.Series.mean(data_train_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_train0[i] > 0: data_train += [data_train0[i]]; price_train += [price_train0[i]]\n"," \n","data_val0 = []; data_val = []; price_val0 = []; price_val = []\n","for i in range(size_val0):\n","    data_val0  += [round(pd.Series.mean(data_val_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n","    price_val0 += [round(pd.Series.mean(data_val_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_val0[i] > 0: data_val += [data_val0[i]]; price_val += [price_val0[i]]\n"," \n","data_test0 = []; data_test = []; price_test0 = []; price_test = []\n","for i in range(size_test0):\n","    data_test0  += [round(pd.Series.mean(data_test_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n","    price_test0 += [round(pd.Series.mean(data_test_csv['Price(€)'][i*unit:(i+1)*unit])/max_price, 3)]\n","    if data_test0[i] > 0: data_test += [data_test0[i]]; price_test += [price_test0[i]]"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ke3I7W_aJPf_"},"outputs":[],"source":["# PPO Agent (Partailly Observable State, Continuous Action Space)\n","# Assumption 1: Standard deviation is fixed\n","# Assumption 2: History is composed of observations only\n"," \n","n_layers         = 2\n","in_size          = 3\n","hidden_size      = 64\n","out_size         = 1\n","T_horizon        = 128\n","learning_rate    = 0.001\n","K_epoch          = 3\n","gamma            = 0.99\n","lmbda            = 0.95\n","eps_clip         = 0.01\n","C_value          = 1\n","var              = 0.1**2\n"," \n","class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.fc_s  = nn.Linear(in_size, hidden_size)\n","        self.rnn   = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n","        self.fc_pi = nn.Linear(hidden_size, out_size)\n","        self.fc_v  = nn.Linear(hidden_size, 1)\n"," \n","    def pi(self, x, hidden):\n","        x = F.relu(self.fc_s(x))\n","        x = x.view(1, -1, hidden_size)\n","        x, hidden = self.rnn(x, hidden)\n","        pi = self.fc_pi(x)\n","        pi = pi.view(-1, out_size)\n","        return pi, hidden\n","    \n","    def v(self, x, hidden):\n","        x = F.relu(self.fc_s(x))\n","        x = x.view(1, -1, hidden_size)\n","        x, hidden = self.rnn(x, hidden)\n","        v = self.fc_v(x)\n","        v = v.view(-1, 1)\n","        return v\n"," \n","def train_net(model, batch, optimizer):\n","    o, H, a, r, o_prime, H_prime, done = [], [], [], [], [], [], []\n","    for transition in batch[0]:\n","        o.append(transition[0])\n","        a.append(transition[1])\n","        r.append([transition[2]])\n","        o_prime.append(transition[3])\n","        done.append([0]) if transition[4] else done.append([1])\n","    for transition in batch[1]:\n","        H.append(transition[0])\n","        H_prime.append(transition[1])\n","        \n","    o         = torch.tensor(o,dtype=torch.float)\n","    H         = (H[0][0].detach(), H[0][1].detach())\n","    a         = torch.tensor(a,dtype=torch.float)\n","    r         = torch.tensor(r,dtype=torch.float)\n","    o_prime   = torch.tensor(o_prime,dtype=torch.float)\n","    H_prime   = (H_prime[0][0].detach(), H_prime[0][1].detach())\n","    done      = torch.tensor(done)\n"," \n","    pdf_old = torch.distributions.MultivariateNormal(model.pi(o, H)[0], var*torch.eye(out_size))\n","    prob_old = torch.exp(pdf_old.log_prob(a)).view(len(a),1)\n","    prob_old = prob_old.detach()\n"," \n","    v_target = r + gamma * model.v(o_prime, H_prime) * done\n","    td = r + gamma * model.v(o_prime, H_prime) * done - model.v(o, H)\n","    td = td.detach().numpy()\n","    advantage = []\n","    A = 0.0\n","    for delta in td[::-1].flatten():\n","        A = delta + gamma*lmbda*A\n","        advantage.append([A])\n","    advantage.reverse()\n","    advantage = torch.tensor(advantage, dtype=torch.float)\n","    \n","    for i in range(K_epoch):\n","        pdf = torch.distributions.MultivariateNormal(model.pi(o, H)[0], var*torch.eye(out_size))\n","        prob = torch.exp(pdf.log_prob(a)).view(len(a),1)\n","        ratio = torch.exp(torch.log(prob) - torch.log(prob_old))  # a/b == exp(log(a)-log(b))\n"," \n","        loss_actor = torch.min(ratio * advantage, torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage)\n","        loss_critic = F.mse_loss(model.v(o, H), v_target.detach())\n","        loss = -(loss_actor - C_value*loss_critic)\n","        \n","        optimizer.zero_grad()\n","        loss.mean().backward(retain_graph=True)\n","        optimizer.step()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"FPSKk3f7JRzp"},"outputs":[],"source":["# Environment\n"," \n","E_max   = Battery_Size\n","P_max   = E_max\n","tdelta  = unit/4\n","soc_min = 0.1\n","soc_max = 0.9\n","a0 = -1.031; a1 = 35; a2 = 3.685; a3 = 0.2156; a4 = 0.1178; a5 = 0.3201\n","b0 = 0.1463; b1 = 30.27; b2 = 0.1037; b3 = 0.0584; b4 = 0.1747; b5 = 0.1288\n","c0 = 0.1063; c1 = 62.49; c2 = 0.0437; d0 = 0.0712; d1 = 61.4; d2 = 0.0288\n","N = 130*215*E_max/0.1\n","beta = 10/max_price\n"," \n","class Env():\n","    def __init__(self, data):\n","        self.data_gen = data[0]\n","        self.data_bid = data[1]\n","        self.data_imb = data[2]\n","        self.state = []\n"," \n","    def reset(self):\n","        gen = self.data_gen[0]\n","        imb = self.data_imb[0]\n","        E = E_max/2\n","        state = [[gen, imb, E]]\n","        self.state = state\n","        return state\n"," \n","    def step(self, action):\n","        gen = self.data_gen[len(self.state)]\n","        bid = self.data_bid[len(self.state)]\n","        bat = action[0]\n","        imb = self.data_imb[len(self.state)]\n","\n","        E = self.state[-1][-1]\n","        soc = E/E_max\n","        Voc = a0*np.exp(-a1*soc) + a2 + a3*soc - a4*soc**2 + a5*soc**3\n","        Rs  = b0*np.exp(-b1*soc) + b2 + b3*soc - b4*soc**2 + b5*soc**3\n","        Rts = c0*np.exp(-c1*soc) + c2\n","        Rtl = d0*np.exp(-d1*soc) + d2\n","        R   = Rs + Rts + Rtl\n","\n","        I_cmax = 1000000*(E_max*soc_max - E)/N/(Voc*tdelta)\n","        I_dmax = 1000000*(E - E_max*soc_min)/N/(Voc*tdelta)\n","        p_cmax = N*(Voc*I_cmax + I_cmax**2*R)\n","        p_dmax = N*(Voc*I_dmax - I_dmax**2*R)\n","\n","        P_cmax = p_cmax/1000000; P_dmax = p_dmax/1000000\n","        P_c = min(max(-bat*E_max, 0), P_max, P_cmax)\n","        P_d = min(max(bat*E_max,  0), P_max, P_dmax)\n","        p_c = 1000000*P_c/N; p_d = 1000000*P_d/N\n","\n","        I_c = -(Voc - np.sqrt(Voc**2 + 4*R*p_c))/(2*R)\n","        I_d = (Voc - np.sqrt(Voc**2 - 4*R*p_d))/(2*R)\n","        if not np.isclose(p_c, 0):\n","            eff_c = (Voc*I_c)/p_c; eff_d = 1\n","            E_prime = E + eff_c*P_c*tdelta\n","            disp = gen - P_c\n","            bid = bid - P_c\n","        elif not np.isclose(p_d, 0):\n","            eff_d = p_d/(Voc*I_d); eff_c = 1\n","            E_prime = E - (1/eff_d)*P_d*tdelta\n","            disp = gen + P_d\n","            bid = bid + P_d\n","        else:\n","            eff_c = 1; eff_d = 1\n","            E_prime = E\n","            disp = gen\n","\n","        revenue = (imb*disp - imb*abs(bid-disp) - beta*(P_c+P_d))*tdelta\n"," \n","        next_state = state + [[gen, imb, E_prime]]\n","        reward = (imb*(P_d-P_c) - beta*(P_c+P_d) - abs(P_c-max(-bat*E_max,0)) - abs(P_d-max(bat*E_max,0)))*tdelta\n","        done = False\n","        info = [gen, bid, bat, disp, revenue]\n"," \n","        self.state = next_state\n","        return next_state, reward, done, info"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CGYeZlJrL_9o"},"outputs":[],"source":["# PPO Training\n","\n","total_episode = 500\n","max_iteration = int(len(data_train)/T_horizon)\n","print_interval = 1\n"," \n","model = LSTM()\n","env_train = Env([data_train, train_predict, price_train])\n","env_val   = Env([data_val, val_predict, price_val])\n","env_test  = Env([data_test, test_predict, price_test])\n","bid_train, bid_val, bid_test = [], [], [] # Bidding Value\n","bat_train, bat_val, bat_test = [], [], [] # Discharging Value\n","mae_train, mae_val, mae_test = [], [], [] # Mean Absolute Error\n","mbe_train, mbe_val, mbe_test = [], [], [] # Mean Bidding Error\n","rev_train, rev_val, rev_test = [], [], [] # Revenue"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"XD7RRZ_WMMee"},"outputs":[{"name":"stdout","output_type":"stream","text":["episode: 1\n","MAE_train: 42.53%        MAE_val: 42.16%          MAE_test: 42.37%         \n","MBE_train: 42.53%        MBE_val: 42.16%          MBE_test: 42.37%         \n","REV_train: $-143.357     REV_val: $-163.331       REV_test: $-167.56       \n","------------------------------------------------------------------------------------------\n","episode: 2\n","MAE_train: 42.51%        MAE_val: 42.15%          MAE_test: 42.36%         \n","MBE_train: 42.53%        MBE_val: 42.16%          MBE_test: 42.37%         \n","REV_train: $-144.338     REV_val: $-163.474       REV_test: $-167.735      \n","------------------------------------------------------------------------------------------\n","episode: 3\n","MAE_train: 42.53%        MAE_val: 42.16%          MAE_test: 42.37%         \n","MBE_train: 42.53%        MBE_val: 42.16%          MBE_test: 42.37%         \n","REV_train: $-144.973     REV_val: $-163.343       REV_test: $-167.584      \n","------------------------------------------------------------------------------------------\n","episode: 4\n","MAE_train: 42.55%        MAE_val: 42.15%          MAE_test: 42.36%         \n","MBE_train: 42.53%        MBE_val: 42.16%          MBE_test: 42.37%         \n","REV_train: $-145.015     REV_val: $-163.431       REV_test: $-167.642      \n","------------------------------------------------------------------------------------------\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m history \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mzeros([n_layers, \u001b[38;5;241m1\u001b[39m, hidden_size], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat), torch\u001b[38;5;241m.\u001b[39mzeros([n_layers, \u001b[38;5;241m1\u001b[39m, hidden_size], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(env_test\u001b[38;5;241m.\u001b[39mdata_gen)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 57\u001b[0m     pi_out, next_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     action \u001b[38;5;241m=\u001b[39m pi_out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     59\u001b[0m     next_state, reward, done, info \u001b[38;5;241m=\u001b[39m env_test\u001b[38;5;241m.\u001b[39mstep(action)\n","Cell \u001b[1;32mIn[12], line 29\u001b[0m, in \u001b[0;36mLSTM.pi\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_s(x))\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_size)\n\u001b[1;32m---> 29\u001b[0m x, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_pi(x)\n\u001b[0;32m     31\u001b[0m pi \u001b[38;5;241m=\u001b[39m pi\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, out_size)\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","for n_epi in range(total_episode):\n","    bid_train += [[]]; bid_val += [[]]; bid_test += [[]]\n","    bat_train += [[]]; bat_val += [[]]; bat_test += [[]]\n","    mae_train += [[]]; mae_val += [[]]; mae_test += [[]]\n","    mbe_train += [[]]; mbe_val += [[]]; mbe_test += [[]]\n","    rev_train += [[]]; rev_val += [[]]; rev_test += [[]]\n"," \n","    state = env_train.reset()\n","    history = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n","    for i in range(max_iteration):\n","        batch = [[],[]]\n","        for t in range(T_horizon):\n","            pi_out, next_history = model.pi(torch.tensor(state[-1], dtype=torch.float), history)\n","            action = np.random.multivariate_normal(pi_out.detach().numpy()[0], var*np.identity(out_size), 1)[0].tolist()\n","            next_state, reward, done, info = env_train.step(action)\n"," \n","            batch[0].append((state[-1], action, reward, next_state[-1], done))\n","            batch[1].append((history, next_history))\n","            state = next_state[:]\n","            history = next_history\n"," \n","            gen = info[0]; bid = info[1]; bat = info[2]; disp = info[3]; revenue = info[4]\n","            bid_train[n_epi] += [bid]\n","            bat_train[n_epi] += [bat]\n","            mae_train[n_epi] += [abs(gen - bid)]\n","            mbe_train[n_epi] += [abs(disp - bid)]\n","            rev_train[n_epi] += [revenue]\n","            if done:\n","                break\n","        \n","        if n_epi != 0:\n","            train_net(model, batch, optimizer)\n","        if done:\n","            break\n","    \n","    state = env_val.reset()\n","    history = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n","    for k in range(len(env_val.data_gen)-1):\n","        pi_out, next_history = model.pi(torch.tensor(state[-1], dtype=torch.float), history)\n","        action = pi_out[0].tolist()\n","        next_state, reward, done, info = env_val.step(action)\n"," \n","        state = next_state[:]\n","        history = next_history\n","        \n","        gen = info[0]; bid = info[1]; bat = info[2]; disp = info[3]; revenue = info[4]\n","        bid_val[n_epi] += [bid]\n","        bat_val[n_epi] += [bat]\n","        mae_val[n_epi] += [abs(gen - bid)]\n","        mbe_val[n_epi] += [abs(disp - bid)]\n","        rev_val[n_epi] += [revenue]\n","    \n","    state = env_test.reset()\n","    history = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n","    for l in range(len(env_test.data_gen)-1):\n","        pi_out, next_history = model.pi(torch.tensor(state[-1], dtype=torch.float), history)\n","        action = pi_out[0].tolist()\n","        next_state, reward, done, info = env_test.step(action)\n"," \n","        state = next_state[:]\n","        history = next_history\n","        \n","        gen = info[0]; bid = info[1]; bat = info[2]; disp = info[3]; revenue = info[4]\n","        bid_test[n_epi] += [bid]\n","        bat_test[n_epi] += [bat]\n","        mae_test[n_epi] += [abs(gen - bid)]\n","        mbe_test[n_epi] += [abs(disp - bid)]\n","        rev_test[n_epi] += [revenue]\n","    \n","    if (n_epi+1)%print_interval == 0:\n","        MAE_train = round(100*np.mean(mae_train[n_epi]),2)\n","        MAE_val   = round(100*np.mean(mae_val[n_epi]),2)\n","        MAE_test  = round(100*np.mean(mae_test[n_epi]),2)\n","        MBE_train = round(100*np.mean(mbe_train[n_epi]),2)\n","        MBE_val   = round(100*np.mean(mbe_val[n_epi]),2)\n","        MBE_test  = round(100*np.mean(mbe_test[n_epi]),2)\n","        REV_train = round(max_price*RE_Capacity1*np.mean(rev_train[n_epi]),3)\n","        REV_val   = round(max_price*RE_Capacity2*np.mean(rev_val[n_epi]),3)\n","        REV_test  = round(max_price*RE_Capacity3*np.mean(rev_test[n_epi]),3)\n"," \n","        print(\"episode: {}\".format(n_epi+1))\n","        print(\"MAE_train: {}%\".format(MAE_train).ljust(25), end=\"\")\n","        print(\"MAE_val: {}%\".format(MAE_val).ljust(25), end=\"\")\n","        print(\"MAE_test: {}%\".format(MAE_test).ljust(25))\n","        print(\"MBE_train: {}%\".format(MBE_train).ljust(25), end=\"\")\n","        print(\"MBE_val: {}%\".format(MBE_val).ljust(25), end=\"\")\n","        print(\"MBE_test: {}%\".format(MBE_test).ljust(25))\n","        print(\"REV_train: ${}\".format(REV_train).ljust(25), end=\"\")\n","        print(\"REV_val: ${}\".format(REV_val).ljust(25), end=\"\")\n","        print(\"REV_test: ${}\".format(REV_test).ljust(25))\n","        print(\"------------------------------------------------------------------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdGyyoIeMQam"},"outputs":[],"source":["# Environment\n"," \n","select_num = np.argmax(np.mean(rev_val[:-1],axis=1))\n","select_test = np.array(bid_test[select_num][:])\n","select_test_bat = np.array(bat_test[select_num][:])\n","select_test_real = np.array(data_test[1:])\n","select_test_price = np.array(price_test[1:])\n"," \n","E = E_max/2\n","mbe = []\n","reward = []\n","info = []\n","for i in range(len(select_test)):\n","    bid = select_test[i]\n","    gen = select_test_real[i]\n","    bat = select_test_bat[i]\n","    imb = select_test_price[i]\n","    \n","    soc = E/E_max\n","    Voc = a0*np.exp(-a1*soc) + a2 + a3*soc - a4*soc**2 + a5*soc**3\n","    Rs  = b0*np.exp(-b1*soc) + b2 + b3*soc - b4*soc**2 + b5*soc**3\n","    Rts = c0*np.exp(-c1*soc) + c2\n","    Rtl = d0*np.exp(-d1*soc) + d2\n","    R   = Rs + Rts + Rtl\n"," \n","    I_cmax = 1000000*E_max*(soc_max - soc)/N/(Voc*tdelta)\n","    I_dmax = 1000000*E_max*(soc - soc_min)/N/(Voc*tdelta)\n","    p_cmax = N*(Voc*I_cmax + I_cmax**2*R)\n","    p_dmax = N*(Voc*I_dmax - I_dmax**2*R)\n"," \n","    P_cmax = p_cmax/1000000; P_dmax = p_dmax/1000000\n","    P_c = min(max(-bat*E_max, 0), P_max, P_cmax)\n","    P_d = min(max(bat*E_max,  0), P_max, P_dmax)\n","    p_c = 1000000*P_c/N; p_d = 1000000*P_d/N\n"," \n","    I_c = -(Voc - np.sqrt(Voc**2 + 4*R*p_c))/(2*R)\n","    I_d = (Voc - np.sqrt(Voc**2 - 4*R*p_d))/(2*R)\n","    if not np.isclose(p_c, 0):\n","        eff_c = (Voc*I_c)/p_c\n","        E = E + eff_c*P_c*tdelta\n","        disp = gen - P_c\n","        info += [[gen, round(bid,4), 'C', round(P_c,4), round(disp,4), round(eff_c,4), round(E,4)]]\n","    elif not np.isclose(p_d, 0):\n","        eff_d = p_d/(Voc*I_d)\n","        E = E - (1/eff_d)*P_d*tdelta\n","        disp = gen + P_d\n","        info += [[gen, round(bid,4), 'D', round(P_d,4), round(disp,4), round(eff_d,4), round(E,4)]]\n","    else:\n","        disp = gen\n","        info += [[gen, round(bid,4), 'N', 'N', round(disp,4), 'N', round(E,4)]]\n","    \n","    mbe += [abs(bid - disp)]\n","    reward += [(imb*disp - imb*abs(bid-disp) - beta*(P_c+P_d))*tdelta]\n"," \n","MAE_test = round(100*np.mean(np.abs(select_test_real - select_test)),2)\n","MBE_test = round(100*np.mean(mbe),2)\n","print(\"MAE_test: {}%\".format(MAE_test))\n","print(\"MBE_test: {}%\".format(MBE_test))\n","print(\"REV_test: ${}\".format(round(max_price*RE_Capacity3*np.mean(reward),3)))\n","\n","result = {}\n","result['1'] = select_test_bat\n"," \n","# pd.DataFrame(result).to_csv(RE+\"_Model2_Arbitrage.csv\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5nAEZOjdtDQBrK7ggqZi/","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
